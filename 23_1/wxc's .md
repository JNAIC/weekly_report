
## 总结：
1. 特征缩放  
         均值归一化： 了解到，通过对特征值的处理，均值归一化，也就是用（xi-avg(平均值)）/（标准差max-min），
                         可以将特征值范围化到接近[-1,1]区间，从而使得梯度下降的速度快
   PS： 正常的假设函数，会遇到三次方，平方根等情况，这个时候，均值归一化，就显得比价重要
2. 关于预测函数的选取：
    1） 可以通过处理特征值， 比如在房价预估上，其实房屋面积更为重要，所以将长和宽两个特征值转成一个特征值（面积）
    2） 通过原始散点图分析，适当选择，比如： 原来数据走向是递增的，那么二次函数可能不太符合 
       （好像后期会具体有关于预测函数选取的方法，不过在那之前，可能就需要由已知幂函数图像选择了）
    3） 预测函数选取后，要对特征值做相应处理
   
3. 判断收敛：
   其实之前小作业，就是大概选取2000次迭代，然后运行，然后手动改了下迭代次数，差不多代价函数没有怎么再降，最后就选取2000次
    课程中：
    1） 通过图像，可以绘制出代价函数关于迭代次数的图像，当下降足够缓慢时停止，
    2） 通过设计函数判断J(θ)于ε（比如0.001）
    PS： 实际过程中并不知道选取ε为多少比较合适，所以推荐图像观察（写导论大作业时看到有的论文最后是有专门一小部分评估拟合程度误差分析）
## 下周计划
  打算把特征值为2个的情况做一下
